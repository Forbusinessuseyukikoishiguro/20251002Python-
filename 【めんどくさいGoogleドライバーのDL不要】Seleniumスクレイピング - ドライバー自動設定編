キーワードやクリエイターで検索


700
メニュー
 投稿

あなただけに表示されています
見出し画像を設定してみませんか?
見出し画像があると、もっと作品のイメージが伝わります！
かんたんにオリジナル画像を作ったり、他のクリエイターが提供した画像から選んだりすることもできます。
ぜひ活用してみましょう！


【めんどくさいGoogleドライバーのDL不要】Seleniumスクレイピング - ドライバー自動設定編

YUKIKO@BI＆AIを極めたい（転職活動中スカウト歓迎）
YUKIKO@BI＆AIを極めたい（転職活動中スカウト歓迎）
2025年10月4日 10:36

【めんどくさいGoogleドライバーのDL不要】Seleniumスクレイピング - ドライバー自動設定編　仮想環境・エラー・初期設定編



目次
【めんどくさいGoogleドライバーのDL不要】Seleniumスクレイピング - ドライバー自動設定編　仮想環境・エラー・初期設定編
1. 必要なライブラリのインストール
2. 基本的なスクレイピングコード(完全版)
3. より実践的な例：動的コンテンツの取得
4. よく使うSeleniumの操作まとめ
5. まとめ
インストール
最小構成コード
1. 仮想環境でSeleniumを動かす方法
2. 必要なライブラリのインストール

すべて表示
SeleniumでChromeDriverを手動ダウンロード不要で使う方法を教えます

以下を学べます

仮想環境を使うやり方

インストール方法（pip install selenium webdriver-manager）

最小構成コード（動く例）

よくあるエラーと対処（Chromeのバージョン、ヘッドレスなど）

docstringを使ったメンテナブルなコードの書き方

1. 必要なライブラリのインストール
# Selenium本体をインストール
pip install selenium

# ドライバーを自動管理してくれる便利なライブラリ
pip install webdriver-manager

copy
なぜwebdriver-managerが便利?

ChromeDriverを自動ダウンロード

バージョンを自動で合わせてくれる

パスの設定不要

2. 基本的なスクレイピングコード(完全版)
# seleniumからwebdriverをインポート(ブラウザを操作するツール)
from selenium import webdriver

# Chromeのオプションを設定するためのクラスをインポート
from selenium.webdriver.chrome.options import Options

# Chromeのサービス設定をインポート
from selenium.webdriver.chrome.service import Service

# webdriver-managerからChromeDriverManagerをインポート(自動ダウンロード用)
from webdriver_manager.chrome import ChromeDriverManager

# HTML要素を探すための方法を指定するクラス
from selenium.webdriver.common.by import By

# 要素が表示されるまで待つための機能
from selenium.webdriver.support.ui import WebDriverWait

# 待機条件を指定するクラス
from selenium.webdriver.support import expected_conditions as EC

# 時間待機用
import time

# ログ出力用
import logging

# ログの基本設定(情報レベル以上を表示、時刻とメッセージを出力)
logging.basicConfig(
    level=logging.INFO,  # INFOレベル以上のログを表示
    format='%(asctime)s - %(levelname)s - %(message)s'  # ログの表示形式
)

# このファイル専用のロガーを作成
logger = logging.getLogger(__name__)


def setup_driver():
    """
    Chromeドライバーをセットアップする関数
    Returns: 設定済みのwebdriverオブジェクト
    """
    # Chromeのオプションを格納するオブジェクトを作成
    chrome_options = Options()
    
    # ヘッドレスモード(画面を表示しない)を有効化
    # コメントアウトすると画面が表示される
    # chrome_options.add_argument('--headless')
    
    # GPU機能を無効化(エラー回避のため)
    chrome_options.add_argument('--disable-gpu')
    
    # サンドボックスを無効化(Linux環境で必要な場合がある)
    chrome_options.add_argument('--no-sandbox')
    
    # 共有メモリの使用を無効化(Dockerなどで必要)
    chrome_options.add_argument('--disable-dev-shm-usage')
    
    # ウィンドウサイズを指定(レスポンシブ対応)
    chrome_options.add_argument('--window-size=1920,1080')
    
    # User-Agentを設定(ボット判定を回避)
    chrome_options.add_argument(
        'user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    )
    
    # 画像を読み込まない設定(高速化)※必要に応じてコメントアウト
    # prefs = {'profile.managed_default_content_settings.images': 2}
    # chrome_options.add_experimental_option('prefs', prefs)
    
    # ChromeDriverを自動でダウンロード&インストール
    # Service()でドライバーサービスを作成
    service = Service(ChromeDriverManager().install())
    
    # webdriverオブジェクトを作成(ブラウザを起動)
    driver = webdriver.Chrome(
        service=service,  # 自動インストールされたドライバーを使用
        options=chrome_options  # 上で設定したオプションを適用
    )
    
    # 暗黙的な待機時間を10秒に設定(要素が見つかるまで最大10秒待つ)
    driver.implicitly_wait(10)
    
    # ログに成功メッセージを出力
    logger.info("Chromeドライバーのセットアップ完了")
    
    # 設定したdriverを返す
    return driver


def scrape_example(url):
    """
    実際にスクレイピングを実行する関数
    Args:
        url: スクレイピングするURL
    """
    # driver変数を初期化(エラー時のクリーンアップ用)
    driver = None
    
    try:
        # ドライバーをセットアップ
        driver = setup_driver()
        
        # 指定されたURLにアクセス
        logger.info(f"アクセス中: {url}")
        driver.get(url)
        
        # ページの読み込みが完了するまで2秒待機
        time.sleep(2)
        
        # ページタイトルを取得
        title = driver.title
        logger.info(f"ページタイトル: {title}")
        
        # 明示的な待機: h1要素が表示されるまで最大10秒待つ
        wait = WebDriverWait(driver, 10)
        h1_element = wait.until(
            EC.presence_of_element_located((By.TAG_NAME, 'h1'))
        )
        
        # h1タグのテキストを取得
        h1_text = h1_element.text
        logger.info(f"H1タグ: {h1_text}")
        
        # 複数の要素を取得する例(全てのリンク)
        # find_elements: 複数の要素を探す(リストで返る)
        links = driver.find_elements(By.TAG_NAME, 'a')
        logger.info(f"リンク数: {len(links)}件")
        
        # 最初の5つのリンクを処理
        for i, link in enumerate(links[:5], 1):
            # href属性を取得
            href = link.get_attribute('href')
            # リンクのテキストを取得
            link_text = link.text
            # ログに出力
            logger.info(f"リンク{i}: {link_text} -> {href}")
        
        # クラス名で要素を探す例
        # 存在しない場合はスキップ
        try:
            # class="content"の要素を探す
            content = driver.find_element(By.CLASS_NAME, 'content')
            # テキストを取得
            content_text = content.text[:100]  # 最初の100文字
            logger.info(f"コンテンツ: {content_text}...")
        except Exception as e:
            # 要素が見つからなかった場合
            logger.warning(f"content要素が見つかりません: {e}")
        
        # CSS Selectorで要素を探す例
        try:
            # CSSセレクターで検索
            items = driver.find_elements(By.CSS_SELECTOR, 'div.item')
            logger.info(f"アイテム数: {len(items)}件")
            
            # 各アイテムを処理
            for i, item in enumerate(items[:3], 1):
                # アイテムのテキストを取得
                item_text = item.text
                logger.info(f"アイテム{i}: {item_text}")
        except Exception as e:
            logger.warning(f"item要素が見つかりません: {e}")
        
        # XPathで要素を探す例
        try:
            # XPathで検索(柔軟な検索が可能)
            paragraphs = driver.find_elements(By.XPATH, '//p')
            logger.info(f"段落数: {len(paragraphs)}件")
        except Exception as e:
            logger.warning(f"段落要素が見つかりません: {e}")
        
        # スクリーンショットを保存
        driver.save_screenshot('screenshot.png')
        logger.info("スクリーンショットを保存しました")
        
        # ページのHTMLソース全体を取得
        page_source = driver.page_source
        logger.info(f"HTMLソースの長さ: {len(page_source)}文字")
        
    except Exception as e:
        # エラーが発生した場合
        logger.error(f"エラーが発生しました: {e}")
        
        # エラー時のスクリーンショットを保存
        if driver:
            driver.save_screenshot('error_screenshot.png')
            logger.info("エラー時のスクリーンショットを保存")
    
    finally:
        # 必ず実行される処理(ブラウザを閉じる)
        if driver:
            # ブラウザを閉じる
            driver.quit()
            logger.info("ブラウザを閉じました")


# このファイルが直接実行された場合のみ以下を実行
if __name__ == "__main__":
    # スクレイピングするURLを指定
    target_url = "https://example.com"
    
    # スクレイピング実行
    scrape_example(target_url)

copy
3. より実践的な例：動的コンテンツの取得
# 必要なライブラリをインポート
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
import logging

# ログ設定
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)


def scrape_dynamic_content():
    """JavaScriptで読み込まれる動的コンテンツをスクレイピング"""
    
    # Chromeオプションを作成
    options = Options()
    
    # ヘッドレスモード(コメントアウトすると画面表示される)
    # options.add_argument('--headless')
    
    # その他の設定
    options.add_argument('--disable-gpu')  # GPU無効化
    options.add_argument('--no-sandbox')  # サンドボックス無効化
    
    # ドライバーを自動セットアップ
    service = Service(ChromeDriverManager().install())
    
    # ドライバーを起動
    driver = webdriver.Chrome(service=service, options=options)
    
    try:
        # 対象ページにアクセス
        logger.info("ページにアクセス中...")
        driver.get("https://example.com")
        
        # 特定の要素が表示されるまで待機(最大15秒)
        wait = WebDriverWait(driver, 15)
        
        # id="content"の要素が表示されるまで待つ
        content_element = wait.until(
            EC.presence_of_element_located((By.ID, 'content'))
        )
        logger.info("コンテンツ要素を発見")
        
        # 要素がクリック可能になるまで待つ
        button = wait.until(
            EC.element_to_be_clickable((By.ID, 'load-more'))
        )
        
        # ボタンをクリック
        button.click()
        logger.info("ボタンをクリック")
        
        # クリック後のコンテンツ読み込みを待つ(3秒)
        time.sleep(3)
        
        # 動的に追加された要素を取得
        new_items = driver.find_elements(By.CLASS_NAME, 'new-item')
        logger.info(f"新しいアイテム: {len(new_items)}件")
        
        # 各アイテムの情報を抽出
        for i, item in enumerate(new_items, 1):
            # テキストを取得
            text = item.text
            # data属性を取得
            data_id = item.get_attribute('data-id')
            
            logger.info(f"アイテム{i}: {text} (ID: {data_id})")
        
        # ページを下にスクロール(無限スクロール対応)
        # 画面の高さを取得
        last_height = driver.execute_script("return document.body.scrollHeight")
        
        # スクロールを3回繰り返す
        for scroll_count in range(3):
            # 一番下までスクロール
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            logger.info(f"スクロール {scroll_count + 1}回目")
            
            # 新しいコンテンツが読み込まれるまで待機
            time.sleep(2)
            
            # 新しい高さを取得
            new_height = driver.execute_script("return document.body.scrollHeight")
            
            # 高さが変わらなければ終了(これ以上コンテンツがない)
            if new_height == last_height:
                logger.info("これ以上コンテンツがありません")
                break
            
            # 高さを更新
            last_height = new_height
        
        # 全てのアイテムを再取得
        all_items = driver.find_elements(By.CLASS_NAME, 'item')
        logger.info(f"合計アイテム数: {len(all_items)}件")
        
    except Exception as e:
        # エラー処理
        logger.error(f"エラー: {e}")
        
        # エラー時のスクリーンショット
        driver.save_screenshot('error.png')
        
    finally:
        # ブラウザを閉じる
        driver.quit()
        logger.info("処理完了")


# 実行
if __name__ == "__main__":
    scrape_dynamic_content()

copy
4. よく使うSeleniumの操作まとめ
"""
Selenium頻出操作チートシート
"""

# === 要素の検索方法 ===

# IDで検索
element = driver.find_element(By.ID, 'element-id')

# クラス名で検索
element = driver.find_element(By.CLASS_NAME, 'class-name')

# タグ名で検索
element = driver.find_element(By.TAG_NAME, 'h1')

# CSSセレクターで検索
element = driver.find_element(By.CSS_SELECTOR, 'div.class > p')

# XPathで検索
element = driver.find_element(By.XPATH, '//div[@class="example"]')

# リンクテキストで検索
element = driver.find_element(By.LINK_TEXT, 'クリックはこちら')

# 部分一致のリンクテキストで検索
element = driver.find_element(By.PARTIAL_LINK_TEXT, 'こちら')

# name属性で検索
element = driver.find_element(By.NAME, 'username')


# === 複数要素の取得 ===

# 複数の要素を取得(リストで返る)
elements = driver.find_elements(By.CLASS_NAME, 'item')

# 各要素を処理
for elem in elements:
    print(elem.text)  # テキストを取得


# === 要素の操作 ===

# クリック
element.click()

# テキスト入力
element.send_keys('入力テキスト')

# テキストをクリアしてから入力
element.clear()  # クリア
element.send_keys('新しいテキスト')  # 入力

# Enter キーを送信
from selenium.webdriver.common.keys import Keys
element.send_keys(Keys.RETURN)


# === 要素の情報取得 ===

# テキストを取得
text = element.text

# 属性を取得
href = element.get_attribute('href')
class_name = element.get_attribute('class')
data_id = element.get_attribute('data-id')

# CSSプロパティを取得
color = element.value_of_css_property('color')


# === 待機処理 ===

# 暗黙的な待機(全ての要素検索に適用)
driver.implicitly_wait(10)  # 10秒

# 明示的な待機
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

wait = WebDriverWait(driver, 10)  # 最大10秒待つ

# 要素が存在するまで待つ
element = wait.until(
    EC.presence_of_element_located((By.ID, 'element-id'))
)

# 要素がクリック可能になるまで待つ
element = wait.until(
    EC.element_to_be_clickable((By.ID, 'button'))
)

# 要素が見えるようになるまで待つ
element = wait.until(
    EC.visibility_of_element_located((By.CLASS_NAME, 'content'))
)


# === JavaScript実行 ===

# JavaScriptコードを実行
driver.execute_script("alert('Hello');")

# スクロール
driver.execute_script("window.scrollTo(0, 500);")  # 500px下へ

# 一番下までスクロール
driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")

# 要素までスクロール
element = driver.find_element(By.ID, 'target')
driver.execute_script("arguments[0].scrollIntoView();", element)


# === その他の操作 ===

# 現在のURLを取得
current_url = driver.current_url

# ページタイトルを取得
title = driver.title

# ページソースを取得
html = driver.page_source

# スクリーンショット
driver.save_screenshot('screenshot.png')

# ブラウザバック
driver.back()

# ブラウザ進む
driver.forward()

# ページ更新
driver.refresh()

copy
5. まとめ
インストール
pip install selenium webdriver-manager

copy
最小構成コード
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager

# ドライバー起動(自動ダウンロード)
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))

# ページアクセス
driver.get("https://example.com")

# 処理...

# 終了
driver.quit()

copy
ポイント:

✅ webdriver-managerで自動ダウンロード

✅ 手動でドライバーをDL不要

✅ バージョン管理も自動

いい感じにまとまってきましたね 👍
ご質問に含まれていた内容を整理すると、

仮想環境でSeleniumを動かす方法

仮想環境を消す方法

必要ライブラリのインストール方法

困ったときに記事にまとめる流れ

docstringの書き方の基本

を知りたい、という理解で合っていますか？

1. 仮想環境でSeleniumを動かす方法
Pythonでスクレイピング環境を汚さず使うには、仮想環境 (venv) を使うのがおすすめです。

# プロジェクト用フォルダ作成
mkdir selenium_scraping
cd selenium_scraping

# 仮想環境作成
python -m venv venv

# 仮想環境を有効化 (Windows)
venv\Scripts\activate

# 仮想環境を有効化 (Mac/Linux)
source venv/bin/activate

copy
仮想環境が有効になると、コマンドラインに (venv) のような表示が出ます。
この状態でライブラリをインストールします。

2. 必要なライブラリのインストール
pip install selenium webdriver-manager

copy
これで selenium と webdriver-manager が仮想環境にインストールされます。

3. Selenium 実行コード（最小構成）
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager


def main():
    """
    Seleniumでブラウザを自動操作するサンプル関数
    """
    # Chromeドライバーを自動でインストールして起動
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))

    # ページアクセス
    driver.get("https://example.com")

    # ページタイトル出力
    print(driver.title)

    # 終了
    driver.quit()


if __name__ == "__main__":
    main()

copy
4. 仮想環境を消す方法
仮想環境を消したいときは、作成したフォルダごと削除すればOKです。

# 仮想環境を抜ける
deactivate

# フォルダごと削除
rm -rf venv

copy
Windowsならエクスプローラで venv フォルダを削除するだけでも大丈夫です。

5. docstring の書き方
docstring は 関数やクラスの説明文 を """ ... """ で書くものです。
基本形は Googleスタイル や NumPyスタイル を使うとわかりやすいです。

Googleスタイル例
def scrape_example(url: str) -> str:
    """
    指定したURLにアクセスしてページタイトルを取得する関数。

    Args:
        url (str): スクレイピング対象のURL

    Returns:
        str: ページタイトル
    """
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))
    driver.get(url)
    title = driver.title
    driver.quit()
    return title

copy
NumPyスタイル例
def scrape_example(url: str) -> str:
    """
    指定したURLにアクセスしてページタイトルを取得する関数。

    Parameters
    ----------
    url : str
        スクレイピング対象のURL

    Returns
    -------
    str
        ページタイトル
    """
    ...

copy
了解です 👍
「Selenium + webdriver-manager」を使うとかなり楽になりますが、それでも環境によってはよくエラーが出ます。記事用に トラブルシューティング集 をまとめておきますね。

✅ Selenium よくあるエラー対応集
1. selenium.common.exceptions.WebDriverException: Message: 'chromedriver' executable needs to be in PATH
原因
chromedriver が見つからない。
手動でドライバーを用意していない場合によく出ます。

解決方法
webdriver-manager をインストールして使う

pip install webdriver-manager

copy
コードを以下のように修正

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager

driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))

copy
2. Chrome のバージョン不一致エラー
SessionNotCreatedException: Message: session not created:
This version of ChromeDriver only supports Chrome version XX

copy
原因
インストールされている Chrome と ChromeDriver のバージョンが一致していない。

解決方法
webdriver-manager が基本的に自動で合わせてくれるので、まずはライブラリを最新にする：

pip install -U webdriver-manager selenium

copy
Chrome自体が古すぎる場合は、ブラウザをアップデートしてください。

3. Linux / Docker環境でブラウザ起動エラー
selenium.common.exceptions.WebDriverException: unknown error: DevToolsActivePort file doesn't exist

copy
原因
サンドボックス関連の権限不足や、GPU利用周りの問題。

解決方法
Chrome起動時のオプションに以下を追加：

from selenium.webdriver.chrome.options import Options

options = Options()
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
options.add_argument("--disable-gpu")

driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

copy
4. ヘッドレスモードで表示が崩れる / 要素が見つからない
原因
ヘッドレスモードだとウィンドウサイズが小さいため、レスポンシブデザインの違うUIが返ってくることがある。

解決方法
ウィンドウサイズを明示的に指定：

options.add_argument("--headless")  # 画面非表示
options.add_argument("--window-size=1920,1080")

copy
5. 要素が見つからない (NoSuchElementException)
原因
ページの読み込みが終わる前に要素を探している。

解決方法
暗黙的な待機

driver.implicitly_wait(10)  # 最大10秒待つ

copy
明示的な待機

from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

wait = WebDriverWait(driver, 15)
element = wait.until(EC.presence_of_element_located((By.ID, "target")))

copy
6. Permission denied / 権限エラー
原因
Linux や Docker で Chrome を実行する際に権限不足。

解決方法
--no-sandbox を追加

必要なら root ユーザー以外で実行

7. SSL 証明書エラー
原因
自己署名証明書などで HTTPS がブロックされている。

解決方法
options.add_argument("--ignore-certificate-errors")

copy
✅ 記事にするときのまとめ例
よくあるトラブル一覧
ドライバーが見つからない → webdriver-manager を使う

Chrome のバージョン不一致 → ブラウザ更新 or webdriver-manager 更新

Linux/Docker で起動失敗 → --no-sandbox, --disable-dev-shm-usage

ヘッドレスでUI崩れ → --window-size を指定

要素が見つからない → 待機処理 (WebDriverWait) を入れる

SSL証明書エラー → --ignore-certificate-errors










YUKIKO@BI＆AIを極めたい（転職活動中スカウト歓迎）
YUKIKO@BI＆AIを極めたい（転職活動中スカウト歓迎）
生成AIパスポート試験合格に向けて学習中！
Python3エンジニア認定試験合格
2025年7月：BIの学習中です！

【技術】
Python/Django/スクレイピング/業務自動化



noteプレミアム
note pro
よくある質問・noteの使い方
プライバシー
クリエイターへのお問い合わせ
フィードバック
ご利用規約
通常ポイント利用特約
加盟店規約
資⾦決済法に基づく表⽰
特商法表記
投資情報の免責事項
【めんどくさいGoogleドライバーのDL不要】Seleniumスクレイピング - ドライバー自動設定編｜YUKIKO@BI＆AIを極めたい（転職活動中スカウト歓迎）
